{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Quadro K2200 (CNMeM is disabled, cuDNN 5103)\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "* Change the working directory to one level above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"/home/rdelaviz/Learning/DL/FastAI/courses/deeplearning1/nbs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size= 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape,y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The labels are not one hot encoded so we need to change to onehot encoded format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.asarray([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "d.shape\n",
    "d.mean()\n",
    "b = np.expand_dims(d,5)\n",
    "print(d.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_line_model():\n",
    "    model = Sequential(\n",
    "        [Lambda(norm_input, input_shape=(1,28,28),output_shape=(1,28,28)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation=\"softmax\")])\n",
    "    model.compile(Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = get_line_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expands the X arrays dimention to 4 dimention otherwise the flow will complain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, 1)\n",
    "X_test = np.expand_dims(X_test, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'tuple'>\n",
      "(64, 1, 28, 28)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "type(batches)\n",
    "img = next(batches)\n",
    "print(type(img))\n",
    "print(img[0].shape)\n",
    "print(img[1].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### img is a batch of images and associated labels, below we plot some of the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACFCAYAAABL2gNbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1db0ffc0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "print(img[0][1][0].shape)\n",
    "fig.add_subplot(1,3,1)\n",
    "imgplot = plt.imshow(img[0][0][0])\n",
    "fig.add_subplot(1,3,2)\n",
    "imgplot = plt.imshow(img[0][1][0])\n",
    "fig.add_subplot(1,3,3)\n",
    "imgplot = plt.imshow(img[0][50][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-88-ef6ebc555f2e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-88-ef6ebc555f2e>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    batches.\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(lm.summary())\n",
    "type(batches)\n",
    "batches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 15s - loss: 0.4261 - acc: 0.8745 - val_loss: 0.3015 - val_acc: 0.9127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1db02f1790>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 18s - loss: 0.2994 - acc: 0.9143 - val_loss: 0.2813 - val_acc: 0.9219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1db03aa750>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 14s - loss: 0.2852 - acc: 0.9195 - val_loss: 0.2805 - val_acc: 0.9224\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 13s - loss: 0.2778 - acc: 0.9229 - val_loss: 0.2771 - val_acc: 0.9215\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 13s - loss: 0.2753 - acc: 0.9227 - val_loss: 0.2776 - val_acc: 0.9229\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 13s - loss: 0.2688 - acc: 0.9257 - val_loss: 0.2699 - val_acc: 0.9251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1db03aa390>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr=0.01\n",
    "lm.fit_generator(batches, batches.n, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Dense Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='softmax'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_5 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "fc = get_fc_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_5 (Lambda)                (None, 1, 28, 28)     0           lambda_input_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 784)           0           lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 512)           401920      flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            5130        dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 15s - loss: 0.8178 - acc: 0.8552 - val_loss: 0.6474 - val_acc: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1da34cbe90>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 14s - loss: 1.1072 - acc: 0.6282 - val_loss: 0.9888 - val_acc: 0.6582\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 15s - loss: 0.9788 - acc: 0.6665 - val_loss: 0.9511 - val_acc: 0.6773\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 13s - loss: 0.9317 - acc: 0.6763 - val_loss: 0.9369 - val_acc: 0.6549\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 15s - loss: 0.9225 - acc: 0.6696 - val_loss: 0.8964 - val_acc: 0.6697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1da26522d0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.optimizer.lr=0.1\n",
    "fc.fit_generator(batches, batches.n, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 14s - loss: 0.8386 - acc: 0.7019 - val_loss: 0.8103 - val_acc: 0.7168\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 15s - loss: 0.8289 - acc: 0.7115 - val_loss: 0.7638 - val_acc: 0.7333\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 15s - loss: 0.8527 - acc: 0.7046 - val_loss: 0.7772 - val_acc: 0.7223\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 15s - loss: 0.8623 - acc: 0.6978 - val_loss: 0.9785 - val_acc: 0.6576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1da24b4750>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.optimizer.lr=0.01\n",
    "fc.fit_generator(batches, batches.n, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 15s - loss: 0.8278 - acc: 0.7059 - val_loss: 0.7575 - val_acc: 0.7150\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 15s - loss: 0.8593 - acc: 0.6997 - val_loss: 0.7869 - val_acc: 0.7236\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 16s - loss: 0.8402 - acc: 0.7013 - val_loss: 0.8145 - val_acc: 0.7204\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 15s - loss: 0.7995 - acc: 0.7143 - val_loss: 0.7500 - val_acc: 0.7287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1da24b4790>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.optimizer.lr=0.005\n",
    "fc.fit_generator(batches, batches.n, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic 'VGG-style' CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_8 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_8 (Lambda)                (None, 1, 28, 28)     0           lambda_input_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 32, 26, 26)    320         lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 32, 24, 24)    9248        convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 32, 12, 12)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 64, 10, 10)    18496       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 64, 8, 8)      36928       convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 64, 4, 4)      0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 1024)          0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 512)           524800      flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 10)            5130        dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 594,922\n",
      "Trainable params: 594,922\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = get_model()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_9 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 27s - loss: 0.1132 - acc: 0.9649 - val_loss: 0.0387 - val_acc: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1da011bbd0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0299 - val_acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d96159b90>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.1\n",
    "model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 29s - loss: 0.0251 - acc: 0.9917 - val_loss: 0.0260 - val_acc: 0.9910\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 28s - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0251 - val_acc: 0.9918\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 26s - loss: 0.0151 - acc: 0.9950 - val_loss: 0.0326 - val_acc: 0.9916.99\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 28s - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0286 - val_acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d96159e90>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.01\n",
    "model.fit_generator(batches, batches.n, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 29s - loss: 0.0114 - acc: 0.9963 - val_loss: 0.0252 - val_acc: 0.9934\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 27s - loss: 0.0096 - acc: 0.9966 - val_loss: 0.0276 - val_acc: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d96159ed0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.005\n",
    "model.fit_generator(batches, batches.n, nb_epoch=2, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_10 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbbUWcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1db1206a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2 = next(batches)\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1,2,1)\n",
    "imgplot = plt.imshow(img[0][0][0])\n",
    "fig.add_subplot(1,2,2)\n",
    "imgplot = plt.imshow(img2[0][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 29s - loss: 0.2076 - acc: 0.9351 - val_loss: 0.0603 - val_acc: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d95d6f490>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 29s - loss: 0.0709 - acc: 0.9781 - val_loss: 0.0494 - val_acc: 0.9855\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 26s - loss: 0.0564 - acc: 0.9824 - val_loss: 0.0476 - val_acc: 0.9845\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 27s - loss: 0.0458 - acc: 0.9851 - val_loss: 0.0502 - val_acc: 0.9853\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 27s - loss: 0.0446 - acc: 0.9864 - val_loss: 0.0417 - val_acc: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d93faf9d0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.1\n",
    "model.fit_generator(batches, batches.n, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 28s - loss: 0.0393 - acc: 0.9876 - val_loss: 0.0313 - val_acc: 0.9901\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 27s - loss: 0.0366 - acc: 0.9883 - val_loss: 0.0311 - val_acc: 0.9906\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 27s - loss: 0.0338 - acc: 0.9899 - val_loss: 0.0364 - val_acc: 0.9896\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 29s - loss: 0.0339 - acc: 0.9893 - val_loss: 0.0391 - val_acc: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d93faf7d0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(batches, batches.n, nb_epoch=4, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchnorm + dropout + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn_do():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_11 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = get_model_bn_do()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.0932 - acc: 0.9721 - val_loss: 0.0455 - val_acc: 0.9860\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 43s - loss: 0.0754 - acc: 0.9763 - val_loss: 0.0474 - val_acc: 0.9858\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 42s - loss: 0.0642 - acc: 0.9801 - val_loss: 0.0374 - val_acc: 0.9881\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 44s - loss: 0.0618 - acc: 0.9812 - val_loss: 0.0389 - val_acc: 0.9866\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 44s - loss: 0.0542 - acc: 0.9829 - val_loss: 0.0331 - val_acc: 0.9892\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 42s - loss: 0.0537 - acc: 0.9835 - val_loss: 0.0313 - val_acc: 0.9897\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 44s - loss: 0.0510 - acc: 0.9846 - val_loss: 0.0344 - val_acc: 0.9879\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 45s - loss: 0.0441 - acc: 0.9864 - val_loss: 0.0343 - val_acc: 0.9897\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 44s - loss: 0.0459 - acc: 0.9861 - val_loss: 0.0267 - val_acc: 0.9918\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 44s - loss: 0.0437 - acc: 0.9868 - val_loss: 0.0373 - val_acc: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d86579250>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(batches, batches.n, nb_epoch=10, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9728/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.026541001514717937, 0.99209999999999998]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??model.evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.4306e-05,   6.2559e-06,   1.6067e-04, ...,   9.9979e-01,   4.0608e-07,   1.1341e-05],\n",
       "       [  3.9882e-06,   4.5923e-06,   9.9999e-01, ...,   7.9640e-09,   1.1923e-08,   1.8024e-09],\n",
       "       [  2.4394e-06,   9.9988e-01,   1.3141e-06, ...,   2.5120e-06,   4.3119e-07,   7.3521e-08],\n",
       "       ..., \n",
       "       [  6.1878e-10,   1.7517e-08,   1.8519e-09, ...,   1.7476e-07,   4.4447e-06,   1.0691e-06],\n",
       "       [  4.9393e-06,   1.8291e-07,   8.4869e-08, ...,   7.7145e-07,   1.8569e-03,   3.2579e-05],\n",
       "       [  2.6533e-06,   1.5906e-08,   3.3004e-07, ...,   2.6319e-08,   4.1703e-05,   5.3153e-08]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.032130928658445676, 0.99039999996821082]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble of methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model_bn_do()\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=1, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    model.optimizer.lr=0.1\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=4, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    model.optimizer.lr=0.01\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=12, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    model.optimizer.lr=0.001\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=18, verbose=0,\n",
    "                        validation_data=test_batches, nb_val_samples=test_batches.n)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_13 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_14 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_15 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_16 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_17 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/rdelaviz/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_18 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "models = [fit_model() for i in range(0,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.getcwd()+\"/RahimModels/mnist/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(model_path+'cnn-mnist23-'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s     \n",
      "10000/10000 [==============================] - 0s     \n",
      "10000/10000 [==============================] - 0s     \n",
      "10000/10000 [==============================] - 0s     \n",
      "10000/10000 [==============================] - 0s     \n",
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "evals = np.array([m.evaluate(X_test, y_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.013 ,  0.9958])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.9969000220298767, dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.categorical_accuracy(y_test, avg_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
